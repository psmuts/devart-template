I have been thinking a lot about where the content/inventory of words will come from and the implications of this decision.  My initial idea was to use words exclusively contributed by participants, but the more I thought about this the more I realized this was less encompassing (and less interesting) that I initially hoped.  Firstly, because using contributions from explicit contributors exclusively seems to exclude more than it includes for a couple of reasons.  a) Because English speakers use only about x0,000 words of the more than 90,000 in the OED, I worry that the set of contributed words would be narrower than desired and b) because, as 

I just am reading about "Big Data" and statistics, and the author (name) makes a great point that n != all and that a web that assumes, because of volume alone, that it is representative of ALL.  That rather it is representative of the subset of say, all who participate, or all who have access to a computer and participate, or all who have access to a computer and the free time etc. etc. you get the point.  

So, I decided I needed access to a source which would include both formally defined and informally used words.  Wordnik offers an API to their datastore of words from both traditional dictionaries as well as words in common usage but without formal definitions.  Using their API, I compiled a dictionary of words in 9 types (list types).  These include words like (super formal) as well as (super informal example.)  

These words, 94000+ classified by type, are then joined (will be) to user contributed words and words culled from Google + tags and FB and Twitter hashtags, though I am still working on selection criteria for these.  

Conceptually, 

We continue to hear about the ways language is changing (some would say de-evolving) because of the new modes of articulation enabled by the web.  Whether it is the idea of everyone posting the most mundane aspects of life in novelly cryptic ways on FB,G+ or the every evolving language of texting (http://www.ted.com/talks/john_mcwhorter_txtng_is_killing_language_jk)  I wanted to find a way then to throw these two worlds together.  That of the inventory of some 60,000-80,000 little used words in English with the evolving language of the web, in the form of 



What I have at this point is a bit of each.  I used a dictionary from (name project, thank authors) which is a randomized selection of nouns, verbs, pronouns, proper nouns, 

It is fun and surprising and stimulating to see the blending of new idiom and expressions from informal speech, posts to social networks, hash tagging, etc. mix with more "traditional" language.  

